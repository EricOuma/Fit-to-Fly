<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!--Social meta tags-->
  <meta property=”og:type” content=”application” />
  <meta property=”og:title” content=”FIT TO INTERACT” />
  <meta property=”og:description” content=”FIT TO INTERACT” />
  <meta property=”og:image” content=”https://github.com/EricOuma/Fit-to-Fly-web” />
  <meta property=”og:url” content=”https://github.com/EricOuma/Fit-to-Fly-web” />
  <meta property=”og:site_name” content=”FIT TO INTERACT” />
  <meta name=”twitter:title” content=”FIT TO INTERACT”>
  <meta name=”twitter:description” content=”FIT TO INTERACT”>
  <meta name=”twitter:image” content=”https://github.com/EricOuma/Fit-to-Fly-web”>
  <meta name=”twitter:site” content=”@EricOuma”>
  <meta name=”twitter:creator” content=”@EricOuma”>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

  <!--MAIN CSS-->
  <link rel="stylesheet" href="css/styles.css">

  <!--Font Awesome-->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" integrity="sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc" crossorigin="anonymous">

  <!--Animation-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.0.0/animate.min.css" />

  <title>Fit to Interact</title>
  <script async src="js/opencv.js" onload="openCvReady()" type="text/javascript"></script>
</head>

<body>
  <div class="container">
    <div id="header" class="col-12 d-flex justify-content-center">
      <img src="img/logo.png" class="site-logo img-fluid pt-4" height="80" width="80" alt="Site Logo" />
    </div>
    <div id="main-section" class="main-section w-100 text-center p-4">
      <h3>Face Identification...</h3>
        <video id="video" class="mr-2 d-none" width="320" height="240"></video>
        <div class="embed-responsive embed-responsive-4by3">
        <canvas id="cvOutput" class="embed-responsive-item"></canvas>
        </div>
      <p>Make sure your face is inside the blue circle.<p>
      <p id="errorMessage"></p>
    </div>
  </div>


  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
  <script src="js/facedetection.js" type="text/javascript"></script>
  <script src="js/utils.js" type="text/javascript"></script>
  <script>
  
  function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  let video = document.getElementById('video');
  var streaming = false
  var handleSuccess = async function(stream) {
    video.srcObject = stream;
    video.play()
    streaming = true
    const canvas = document.createElement('canvas');
    const context = canvas.getContext('2d');
    context.drawImage(video, 0, 0, canvas.width, canvas.height);
  };
  
  
  function openCvReady() {
    cv['onRuntimeInitialized'] = async () => {
    navigator.mediaDevices.getUserMedia({
        audio: false,
        video: true
      })
      .then(handleSuccess).then(() => {
          let canvasOutput = document.getElementById("cvOutput");
          let canvasContext = canvasOutput.getContext('2d');
          let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
          let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
          let gray = new cv.Mat();
          let cap = new cv.VideoCapture(video);
          let faces = new cv.RectVector();
          let classifier = new cv.CascadeClassifier();
          
          // load pre-trained classifiers
          //classifier.load('docs/haarcascade_frontalface_default.xml');
          //console.log(classifier.empty())
          
          let utils = new Utils('errorMessage'); //use utils class
          let faceCascadeFile = 'docs/haarcascade_frontalface_default.xml'; // path to xml
          
          // use createFileFromUrl to "pre-build" the xml
          //Make sure to run it in a webserver because it has to do XMLHTTPRequests.
          utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
              classifier.load(faceCascadeFile); // in the callback, load the cascade from file 
        });
          
          const FPS = 30;
          function processVideo() {
            try {
                if (!streaming) {
                    // clean and stop.
                    console.log('Clean and stop')
                    src.delete();
                    dst.delete();
                    gray.delete();
                    faces.delete();
                    classifier.delete();
                    return;
                }
                let begin = Date.now();
                // start processing.
                cap.read(src);
                src.copyTo(dst);
                cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
                // detect faces.
                classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                // draw faces.
                for (let i = 0; i < faces.size(); ++i) {
                    let face = faces.get(i);
                    let point1 = new cv.Point(face.x, face.y);
                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                    cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                }
                cv.imshow('cvOutput', dst);
                canvasContext.beginPath();
                canvasContext.arc(160, 120, 100, 0, 2 * Math.PI);
                canvasContext.lineWidth = 3;
                canvasContext.strokeStyle = "blue";
                canvasContext.stroke();
                // schedule the next one.
                let delay = 1000/FPS - (Date.now() - begin);
                setTimeout(processVideo, delay);
            } catch (err) {
                utils.printError(err);
            }
          };
          
          // schedule the first one.
          setTimeout(processVideo, 0);
      });
      // pause here until streaming is true
  
    };
  }
  
  
  </script>

</body>

</html>
